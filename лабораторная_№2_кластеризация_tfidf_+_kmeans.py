# -*- coding: utf-8 -*-
"""TfIdf + Kmeans

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19O_F8XVRKj5FneI9BPIcayJ8G0ewp6l5

## Импорт библиотек
"""

!pip install yellowbrick

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score, adjusted_rand_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from yellowbrick.cluster import KElbowVisualizer
import re
import string
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer, SnowballStemmer

nltk.download('stopwords')

"""## Загрузка датасета"""

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Combined Data 1.csv', index_col=0)

df1 = df.copy()
df1.dropna(inplace = True)
#df1 = df1.drop('status', axis=1) # опускаем столбец с лейблами
df1.head()

"""## Препроцессинг"""

def clean_text(text):

    # Convert to string and lowercase
    text = str(text).lower()

    # Remove text in square brackets
    text = re.sub(r'\[.*?\]', '', text)

    # Remove URLs (including markdown-style links)
    text = re.sub(r'https?://\S+|www\.\S+|\[.*?\]\(.*?\)', '', text)

    # Remove HTML tags
    text = re.sub(r'<.*?>+', '', text)
    # Remove handles (that start with '@')
    text = re.sub(r'@\w+', '', text)

    # Remove punctuation and other special characters
    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)

    # Remove newline characters
    text = re.sub(r'\n', ' ', text)

    # Remove words containing numbers
    text = re.sub(r'\w*\d\w*', '', text)

    # Remove extra spaces
    text = re.sub(r'\s+', ' ', text)

    return text.strip()

stop_words = stopwords.words('english')
more_stopwords = ['u', 'im', 'c']
stop_words = stop_words + more_stopwords

stemmer = nltk.SnowballStemmer("english")

def preprocess_data(text):
    #Clean puntuation, urls, and so on
    text = clean_text(text)
    # Remove stopwords
    text = ' '.join(word for word in text.split(' ') if word not in stop_words)
    # Stemm all the words in the sentence
    text = ' '.join(stemmer.stem(word) for word in text.split(' '))

    return text

df2 = df1.copy()

df2['statement_clean'] = df2['statement'].apply(preprocess_data)

"""## Векторизация текстовых данных"""

documents = df2['statement_clean'].to_list()

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df2['statement_clean'])
X

pca = PCA(n_components=2)
PCA = pca.fit(X.toarray())
X_pca = pca.transform(X.toarray())

labels = df2['status']
encoder = LabelEncoder()
true_labels = encoder.fit_transform(labels)

kmeans = KMeans()
visualizer = KElbowVisualizer(kmeans, k=(1,10),size=(1080, 500))

visualizer.fit(X_pca)
visualizer.show()

silhouette = []
K = range(2,10)

for k in K:
    kmeanModel = KMeans(n_clusters=k)
    preds = kmeanModel.fit_predict(X_pca)
    silhouette.append(silhouette_score(X_pca, preds))

plt.figure(figsize=(20,5))
plt.plot(K, silhouette, '-',color='g')
plt.xlabel('k values')
plt.ylabel('Silhouette score')
plt.title('Silhouette score of each k values')
plt.show()

cluster_analyzer = KMeans(n_clusters=3, init='k-means++', random_state=42)
clusters = cluster_analyzer.fit_predict(X_pca)

cluster_centers = cluster_analyzer.cluster_centers_
labels = cluster_analyzer.labels_

plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis')
plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], c='red', marker='X', s=20)
plt.show()

silhouette = silhouette_score(X_pca, clusters)
ari = adjusted_rand_score(true_labels, clusters)

print(f"Silhouette Score: {silhouette:.2f}")
print(f"Adjusted Rand Index: {ari:.2f}")

"""При "оптимальном" количестве кластеров (3):
Silhouette Score: 0.47
Adjusted Rand Index: 0.21

При истинном количестве кластеров (7):
Silhouette Score: 0.43
Adjusted Rand Index: 0.27
"""